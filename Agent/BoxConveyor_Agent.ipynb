{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfb722f",
   "metadata": {},
   "source": [
    "# 1 - Importa bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.nn import Tanh, ELU, ReLU, Sigmoid, Softmax\n",
    "import websocket\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import gym\n",
    "import stable_baselines3\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Tuple, MultiDiscrete\n",
    "from stable_baselines3 import PPO, DQN, A2C, SAC, TD3, DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList, ProgressBarCallback, TensorboardCallback, EvalCallback\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from sb3_contrib import RecurrentPPO, TQC, QRDQN, MaskablePPO, TRPO, ARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e4626",
   "metadata": {},
   "source": [
    "# 2 - Cria funções de encoding/decoding em json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):            \n",
    "            return obj.tolist()\n",
    "        \n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "identifier ='BoxConveyor_manual'\n",
    "actions =[]\n",
    "message = ''\n",
    "\n",
    "\n",
    "def encode_json(identifier, actions):\n",
    "    data = {}\n",
    "    data['identifier'] = identifier\n",
    "    data['actions'] = actions\n",
    "    json_data = json.dumps(data, cls=NumpyEncoder)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12bf18",
   "metadata": {},
   "source": [
    "# 3 - Define função de criação do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrillEnv(Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def _reset(self):\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.action_name = ''\n",
    "        self.Can = False\n",
    "        self.SensorHandling = False\n",
    "        self.SensorRobot = False\n",
    "        self.ConveyorPosition = 0\n",
    "        actions = []\n",
    "        self.number_steps = 0\n",
    "        self.buffer_size = tamanho_buffer        \n",
    "        self.state_buffer = np.zeros((self.buffer_size * 4))\n",
    "        \n",
    "    def _obs(self):\n",
    "        obs= self.state_buffer                     \n",
    "        return obs\n",
    "        \n",
    "\n",
    "    def setprint(self, print):\n",
    "        self.print = print \n",
    "    def setprint2(self, print):\n",
    "        self.print2 = print\n",
    "    \n",
    "    def __init__(self):     \n",
    "        super(DrillEnv, self).__init__()\n",
    "        self.reset()\n",
    "\n",
    "        self.print = False\n",
    "        self.print2 = False\n",
    "        self.action_space = Discrete(3)       \n",
    "        self.observation_space = Box(low=0, high=1, shape=(1,self.buffer_size * 4), dtype=np.float32)\n",
    "\n",
    "\n",
    "    def buffer(self, Can,SensorHandling, SensorRobot, ConveyorPosition):\n",
    "        \n",
    "        self.state_buffer = np.roll(self.state_buffer,4)\n",
    "         \n",
    "        self.state_buffer[0] = Can \n",
    "        self.state_buffer[1] = SensorHandling \n",
    "        self.state_buffer[2] = SensorRobot\n",
    "        self.state_buffer[3] = ConveyorPosition \n",
    "\n",
    "    def step(self, action):\n",
    "        actions = action \n",
    "        self.number_steps += 1\n",
    "        mensagem = encode_json('BoxConveyor_manual',  [actions])\n",
    "        \n",
    "        ws.send(mensagem)\n",
    "        data =''\n",
    "        station_identifier = ''\n",
    "        while  station_identifier != 'BoxConveyor':\n",
    "            try:\n",
    "                data = json.loads(ws.recv())                \n",
    "                station_identifier = (data['identifier'])\n",
    "            except:\n",
    "                return\n",
    "        \n",
    "        self.reward = int(data['reward'])\n",
    "         \n",
    "        if bool(data['done']) == False:\n",
    "            done = False\n",
    "        else:\n",
    "            done = True\n",
    "               \n",
    "        self.Can = bool(data['states'][0])\n",
    "        self.SensorHandling = bool(data['states'][1])\n",
    "        self.SensorRobot = bool(data['states'][2])\n",
    "        self.ConveyorPosition = float(data['states'][3])\n",
    "    \n",
    "        self.buffer(self.Can, self.SensorHandling, self.SensorRobot,self.ConveyorPosition) \n",
    "\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        obs=self._obs()\n",
    "        \n",
    "        actions_dict = {\n",
    "                            0: {'Forward': False, 'Backward': False},\n",
    "                            1: {'Forward': True, 'Backward': False},\n",
    "                            2: {'Forward': False, 'Backward': True}\n",
    "                        }\n",
    "        \n",
    "        \n",
    "        if self.print:  \n",
    "            print((self.number_steps),'recompensa: ',(self.reward),'|  acao --> ', actions_dict[actions],'  done: ', done)\n",
    "            for name, value in zip(['Can', 'SensorHandling', 'SensorRobot', 'ConveyorPosition'], self.state_buffer[0:4]):\n",
    "                print(f\"{name}: {value}\")\n",
    "            print('\\n')\n",
    "   \n",
    "         # Return step information\n",
    "        return obs, self.reward, done, info\n",
    "    \n",
    "    def render(self , mode):\n",
    "        pass\n",
    "    def reset(self):        \n",
    "        self._reset()\n",
    "        return self._obs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d2da0",
   "metadata": {},
   "source": [
    "# 4 - Cria o modelo em Aprendizagem por Reforço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc52410",
   "metadata": {},
   "outputs": [],
   "source": [
    "algoritmo = PPO\n",
    "nome_do_ficheiro = \"PPO\"\n",
    "tamanho_buffer = 6 # tamanho do buffer aplicado ao algoritmo\n",
    "funcao_ativacao = Tanh #ex: Tanh, ELU, ReLU, Sigmoid, Softmax\n",
    "rede_neuronal=[dict(pi=[60,60], vf=[60,60])] # define número de nurónios na rede neuronal de política e rede neuronal de valor\n",
    "tipo_camadas = 'MlpPolicy' # define o tipo de camadas do modelo !!---(Para modelo em PPORecurrent, usar MlpLstmPolicy)---!!\n",
    "fator_desconto= 0.95 #fator de desconto para aprendizagem por reforço\n",
    "save_path = os.path.join('Training_BoxConveyor','Model_saves',f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training_BoxConveyor','Model_saves',f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}\"\"\")\n",
    "policy_kwargs = dict(activation_fn=funcao_ativacao,net_arch=rede_neuronal)\n",
    "log_path = os.path.join('Training_BoxConveyor','Logs',f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}\"\"\")\n",
    "\n",
    "env=DrillEnv()\n",
    "env.setprint(False) ### imprime os estados e ações\n",
    "env=DummyVecEnv([lambda: env])\n",
    "env.reset()\n",
    "\n",
    "\n",
    "model=algoritmo(tipo_camadas,env,verbose=1,\n",
    "        gamma=fator_desconto, gae_lambda=0.95,\n",
    "        seed=9,policy_kwargs=policy_kwargs, \n",
    "        tensorboard_log=log_path)\n",
    "\n",
    "\n",
    "print(model.policy)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1e886",
   "metadata": {},
   "source": [
    "# 5 - Define funções de callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a689d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=10000,\n",
    "  save_path=os.path.join('Training_BoxConveyor','Model_saves',f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}_checkpoint\"\"\"),\n",
    "  name_prefix=f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}_checkpoint\"\"\")\n",
    "\n",
    "\n",
    "eval_callback = EvalCallback(env, n_eval_episodes=3,\n",
    "                             best_model_save_path=os.path.join('Training_BoxConveyor','Model_saves',f\"\"\"{nome_do_ficheiro}_B{tamanho_buffer}_backup\"\"\",'Best_model'),\n",
    "                             log_path=log_path, eval_freq=4096,\n",
    "                             deterministic=False, render=False)\n",
    "callback = CallbackList([checkpoint_callback, ProgressBarCallback(), TensorboardCallback(), eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf4189",
   "metadata": {},
   "source": [
    "# 6 - Inicia treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 15000 ### define número de passos para treino\n",
    "\n",
    "ws = websocket.WebSocket()\n",
    "\n",
    "ws.connect(\"ws://127.0.0.1:12000\")\n",
    "time.sleep(1)\n",
    "\n",
    "for i in range(1):\n",
    "    model.learn(total_timesteps=n_steps,log_interval=200,callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac8bd0",
   "metadata": {},
   "source": [
    "# 7 - Salva o modelo (caso necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe450c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964f894",
   "metadata": {},
   "source": [
    "# 8 - Carrega o modelo (caso necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_do_ficheiro_carregar = \"PPO\" ###\n",
    "algoritmo_carregar = PPO ### Algoritmo a carregar\n",
    "tamanho_buffer_carregar = 6\n",
    "\n",
    "####------------------------------------***----------------------------------------------------####\n",
    "\n",
    "tamanho_buffer = tamanho_buffer_carregar\n",
    "load_path = os.path.join('Training_BoxConveyor','Model_saves',f\"\"\"{nome_do_ficheiro_carregar}_B{tamanho_buffer_carregar}\"\"\")\n",
    "model = algoritmo_carregar.load(load_path)\n",
    "print(\"Carregando ficheiro: \",nome_do_ficheiro_carregar, \"no caminho: \", load_path)\n",
    "print(\"\\n\",\"*\" * 100,\"\\n\" )\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa0b4",
   "metadata": {},
   "source": [
    "# 9 - Utiliza modelo treinado no ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c071c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env=DrillEnv()\n",
    "env.setprint(True) ### Imprime estados e ações\n",
    "env=DummyVecEnv([lambda: env])\n",
    "env.reset()\n",
    "\n",
    "  \n",
    "ws = websocket.WebSocket()\n",
    "ws.connect(\"ws://127.0.0.1:12000\")\n",
    "time.sleep(1)\n",
    "mensagem = encode_json('CanConveyor_automatico', []) ### Para deixar a esteira de latas no modo automático\n",
    "ws.send(mensagem)\n",
    "mensagem = encode_json('Handling_automatico', []) ### Para deixar a garra de latas no modo automático\n",
    "time.sleep(1)\n",
    "ws.send(mensagem)\n",
    "obs = env.reset()\n",
    "while True: \n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render() \n",
    "    if done: \n",
    "        obs = env.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba24a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
